{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid19 - Twitter data extraction\n",
    "by Victoria, Maha, Gopi\n",
    "\n",
    "## Table of contents\n",
    "- Introduction\n",
    "- Authenticatications\n",
    "    - Twitter\n",
    "    - Google sheets\n",
    "- Gathering data & storing\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This notebook is part of the project developed for the FLT Big Data Hackathon, whose objective is to create interesting and trustworthy analyses and visualizations about the COVID19 situation and its correlation with the stock market. \n",
    "\n",
    "In this notebook we use the Twitter API to retrieve the tweets related to COVID19 hashtags and economic tags, to perform a sentimental analysis and store it programatically in a google sheets file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aravind/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load important libraries\n",
    "import gspread \n",
    "from df2gspread import df2gspread as d2g\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import json\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from tweepy import Stream\n",
    "from tweepy import StreamListener\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "from  geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "import pycountry\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "jqdQzdqytO88",
    "outputId": "b46f1541-50e8-4fe4-a091-00175482cd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n",
      "printing tweets from timeline \n",
      " \n",
      "Good 12 PM Tweepy\n",
      "\n",
      "Good evening Tweepy\n",
      "\n",
      "Hello Tweepy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load twitter credentials\n",
    "with open(\"covid19-sentanalysis-twitter_credentials.json\") as datafile:\n",
    "  data = json.load(datafile)\n",
    "\n",
    "# Define the keys\n",
    "consumer_key= data['consumer_key'] #'API_CONSUMER_KEY_HERE'\n",
    "consumer_secret=  data['consumer_secret']#'CONSUMER_SECRET_HERE'\n",
    "\n",
    "access_token= data['access_token_key'] #'ACCESS_TOKEN_HERE'\n",
    "access_token_secret= data['access_token_secret'] #'ACCESS_TOKEN_SECRET_HERE'\n",
    "\n",
    "\n",
    "#Crate the auth object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# create API, set limits to avouid errors because of a timeout \n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")\n",
    "\n",
    "#Print 5 tweets for testing purposes - Should be deleted afterwards\n",
    "home_tweets = api.home_timeline(count=5)\n",
    "print(\"printing tweets from timeline \\n \")\n",
    "for tweet in home_tweets:\n",
    "    print(tweet.text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = [\n",
    "   'https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "#authenticate gsheets\n",
    "google_key_file = 'service_key.json'\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(google_key_file, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# Define spreadsheet access\n",
    "spreadsheet_key = '1auoQ9XanosnM7RUInzqeZi9EIgwtCtmtubNpXrfF6OM' \n",
    "wks_name = 'sentimentAnalysis'\n",
    "\n",
    "# Open the file\n",
    "book = gc.open_by_key(spreadsheet_key) \n",
    "worksheet = book.worksheet(wks_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlNcN1cx0uOD"
   },
   "source": [
    "## Gathering data & storing\n",
    "**GET Twitter Stream and Do Sentiment Analysis in Real time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huknvBk9Y8bj"
   },
   "outputs": [],
   "source": [
    "trump = 0\n",
    "warren = 0\n",
    "\n",
    "header_name = ['id', 'user_id','Text','created_at','timestamp','location','latitude','longitude','country','country_code','followers_count','Trump','Warren']\n",
    "\n",
    "class Listener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_tweets = 30\n",
    "        self.tweet_count = 0\n",
    "        self.geolocator = Nominatim()\n",
    "        self.tweet_list = []\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        raw_twitts = json.loads(data)\n",
    "        try:\n",
    "            #  Fields we need: id, created_at, text, coordinates, author_id\n",
    "            full_tweets = raw_twitts.copy()\n",
    "            # TO DO: we must drop from full_tweets the tweets that consist only on RT, numbers, etc (see regex used below)\n",
    "            tweets = raw_twitts['text']\n",
    "            tweets = ' '.join(re.sub(\"(@[A-Za-z0-9]+) | ({*0-9A-Za-z \\t]) |] (\\wt:\\/\\/\\St+)\", \" \", tweets).split())\n",
    "            tweets = ' '.join(re.sub('RT',' ', tweets).split())  \n",
    "  \n",
    "  \n",
    "            blob = TextBlob(tweets.strip())\n",
    "            global trump\n",
    "            global warren\n",
    "  \n",
    "            trump_sentiment = 0\n",
    "            warren_sentiment = 0\n",
    "  \n",
    "            for sent in blob.sentences:\n",
    "                if \"Trump\" in sent and \"Warren\" not in sent:\n",
    "                    trump_sentiment = trump_sentiment + sent.sentiment.polarity\n",
    "                else:\n",
    "                    warren_sentiment = warren_sentiment + sent.sentiment.polarity\n",
    "    \n",
    "            trump = trump + trump_sentiment\n",
    "            warren = warren + warren_sentiment\n",
    "  \n",
    "            #get timestamp from created_at\n",
    "            time_created_at = raw_twitts['created_at']\n",
    "            t = time_created_at.split('+0000 ')\n",
    "            time = t[0] +t[1]\n",
    "            format_time = '%a %b %d %H:%M:%S %Y'\n",
    "            date_time = datetime.strptime(time,format_time)\n",
    "            ts = int(date_time.timestamp())\n",
    "            \n",
    "            #get lat, long from location\n",
    "            lat = None\n",
    "            long = None\n",
    "            if raw_twitts['user']['location']:\n",
    "                loc = self.geolocator.geocode(raw_twitts['user']['location'])\n",
    "                if loc:\n",
    "                    lat = loc.latitude\n",
    "                    long = loc.longitude\n",
    "                    location = self.geolocator.reverse(str(lat)+','+str(long))\n",
    "                    country = location.raw['address']['country']\n",
    "                    #country name may be official name or name. \n",
    "                    #So, try to get the country code using both, if couldn't find then set code to None.\n",
    "                    #Some countries have symbols, so better to keep None if not found using above method\n",
    "                    if country:\n",
    "                        country_official_name = pycountry.countries.get(official_name=country)\n",
    "                        if country_official_name:\n",
    "                            country_code = country_official_name.alpha_3\n",
    "                        else:\n",
    "                            country_name = pycountry.countries.get(name=country)\n",
    "                            if country_name:\n",
    "                                country_code = country_name.alpha_3\n",
    "                            else:\n",
    "                                country_code = None\n",
    "                    else:\n",
    "                        country_code = None\n",
    "            \n",
    "            if lat and long:\n",
    "                info = {'id':raw_twitts['id'],\n",
    "                            'user_id':raw_twitts['user']['id'], \n",
    "                            'Text':raw_twitts['text'],\n",
    "                            'created_at':raw_twitts['created_at'],\n",
    "                            'timestamp':ts,\n",
    "                            'location':raw_twitts['user']['location'],\n",
    "                            'latitude':lat,\n",
    "                            'longitude':long,\n",
    "                            'country': country,\n",
    "                            'country_code': country_code,\n",
    "                            'followers_count':raw_twitts['user']['followers_count'],\n",
    "\n",
    "                            'Trump': trump,\n",
    "                            'Warren': warren}\n",
    "                self.tweet_list.append(info)\n",
    "  \n",
    "            print (tweets,'\\n')    \n",
    "        except:\n",
    "            print('ERROR got')\n",
    "        else:\n",
    "            self.tweet_count+=1\n",
    "                # Once it reaches a fix limit the Write the data into gsheets\n",
    "            if(self.tweet_count==self.max_tweets):          \n",
    "                # save to a dataframe for eeasier file upload\n",
    "                  df_tweet_list = pd.DataFrame(self.tweet_list, columns = header_name)\n",
    "            \n",
    "                  values = df_tweet_list.values.tolist()\n",
    "                  book.values_append(wks_name, {'valueInputOption': 'USER_ENTERED'}, {'values': values})\n",
    "                \n",
    "                 #d2g.upload(df_tweet_list, spreadsheet_key, wks_name, clean =True, credentials=credentials, row_names=False)\n",
    "            \n",
    "                  print(\"completed\")\n",
    "                  return(False)\n",
    "            else:\n",
    "                decoded = json.loads(data)\n",
    "\n",
    "        def on_error(self, status):\n",
    "            print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-MAEzOxY9k9"
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jE5iBNqMY-D5",
    "outputId": "192cc8f0-3c22-4cd0-e3c2-ea65a512c153"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aravind/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Using Nominatim with the default \"geopy/1.22.0\" `user_agent` is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`. In geopy 2.0 this will become an exception.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May we all have a safe eid celebration. And we all get the joy of giving, sharing and helping people in these tough… https://t.co/LmzvORBLjV \n",
      "\n",
      "@ every single government minister tomorrow https://t.co/yFiqXNeZPE \n",
      "\n",
      "@JuliaHB1: My 77yr old mum, who lives on her own, had a heart attack in December &amp;, thanks to the coronavirus risk &amp; lockdown, I hadn’t… \n",
      "\n",
      "No... But travelling over 200 miles with symptoms of covid is thoughtless.... Stay at home \n",
      "\n",
      "@DrZweliMkhize: As of today, the total number of confirmed #COVID19 cases in South Africa is 21 343, the total number of deaths is 407 a… \n",
      "\n",
      "@SniperDelmo: Who needs a banner like this? $15, full price goes to people who are being affected with COVID 🥺 Banner would be made by… \n",
      "\n",
      "@FranJWilliams: @Kent_Online Thousands of people in this country had elderly, ill, terminal ill, newborn family members, funerals they c… \n",
      "\n",
      "@humpleupagus: This COVID thing is absolutely out of control! This guy was just arrested for not washing his hands! 🤬 https://t.co/w2ao4… \n",
      "\n",
      "Happen in September right now. #limboland #university #COVID19 \n",
      "\n",
      "@lewis_goodall: Mirror now reporting that Mr Cummings went to County Durham a second time and was seen walking in local woods. If so wou… \n",
      "\n",
      "@williamcrawley: Is this arrogance or political resilience? \n",
      "\n",
      "@morethanmySLE: Can you believe that, with all of the problems and difficulties facing the U.S. from #COVID19 , President Trump spent th… \n",
      "\n",
      "@Macerty: Johnson is in for one hell of a humiliating beating in parliament at next Wednesday’s PMQT if he tries to ride this one out ov… \n",
      "\n",
      "If only he has the gumption to take it, Johnson has an easy way to outmanoeuvre the hard-Left unions who oppose pla… https://t.co/eM4dzZsOIN \n",
      "\n",
      "@peterkyle: Unsurprisingly there’s more. So, he: - didn’t ‘stay home’ 🤦🏻‍♂️ - travelled unlawfully 🤬 - drove to exercise unlawfully… \n",
      "\n",
      "@ElitatheLibra: I’m at Publix. Someone dropped a package of pre-cut watermelon and it’s spread all over the shelf. Someone walked over a… \n",
      "\n",
      "@ZoraSuleman: Lol Its being claimed Dominic Cummings ignored coronavirus lockdown rules for a second time to visit his parents - around… \n",
      "\n",
      "@soledadobrien: The teachers are often older than 25. The lunch ladies, the support staff, the janitorial staff, the administrators, the… \n",
      "\n",
      "@GretaThunberg: “We need to make an effort while we are in this calm moment in terms of press coverage, because they are only talking ab… \n",
      "\n",
      "@JoeBiden: The hard truth is Donald Trump ignored the warnings of health experts and intelligence agencies, downplayed the threat COVID-… \n",
      "\n",
      "So what is your explanation for this, then? https://t.co/naieGoDuPb \n",
      "\n",
      "Sorry, aren’t you watching lockdown party? \n",
      "\n",
      "after this covid shit is done imma frame my mask and title it “IYKYK” \n",
      "\n",
      "@cuban_manny: Michigan’s AG Dana Nessel overstepped her authority by telling to wear a mask at the Ford Plant this week… \n",
      "\n",
      "@k8_lister: I’m not even angry that #dominiccummimgs disregarded lockdown rules. Fuck him, he’s a twat. What angers me is the government… \n",
      "\n",
      "@GretaThunberg: “We need to make an effort while we are in this calm moment in terms of press coverage, because they are only talking ab… \n",
      "\n",
      "@RachelBitecofer: Yes. Keep in mind, our enemies know we’re domestically breaking down via hyperpartisanship &amp; polarization &amp; they’re we… \n",
      "\n",
      "@wef: #COVID19 is not a break for nature – let’s make sure there is one after the crisis #biodiversityday https://t.co/EzHj8uFqGJ https:… \n",
      "\n",
      "@ClarkeMicah: 2/2 Hypocrisy was inevitable from the start. Solution is not to demand such follies in the first place. \n",
      "\n",
      "@cricketpakcompk: #BreakingNews Tauqfeeq Umar tests positive for Covid-19 #Pakistan #Covid_19 https://t.co/OpuJ0HQlRv \n",
      "\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "twitter_stream = Stream(auth, Listener())\n",
    "twitter_stream.filter(track = ['covid', 'covid19','economic pandemic','chinese virus impact', 'lockdown', 'lockdown recession'], languages=['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(alpha_2='DE', alpha_3='DEU', name='Germany', numeric='276', official_name='Federal Republic of Germany')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycountry.countries.get(alpha_2='DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "twitter_data_extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
